{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Take-notice!\" data-toc-modified-id=\"Take-notice!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Take notice!</a></span></li><li><span><a href=\"#Sentiment-Analysis\" data-toc-modified-id=\"Sentiment-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sentiment Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bring-in-the-libraries\" data-toc-modified-id=\"Bring-in-the-libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bring in the libraries</a></span></li></ul></li><li><span><a href=\"#Twitter-with-tweepy\" data-toc-modified-id=\"Twitter-with-tweepy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Twitter with tweepy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tweets-by-username\" data-toc-modified-id=\"Tweets-by-username-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tweets by username</a></span></li><li><span><a href=\"#Tweets-by-keyword\" data-toc-modified-id=\"Tweets-by-keyword-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Tweets by keyword</a></span></li><li><span><a href=\"#Tweets-by-keyword-and-place\" data-toc-modified-id=\"Tweets-by-keyword-and-place-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Tweets by keyword and place</a></span></li></ul></li><li><span><a href=\"#The-tweet-object\" data-toc-modified-id=\"The-tweet-object-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The tweet object</a></span><ul class=\"toc-item\"><li><span><a href=\"#Word-Cloud\" data-toc-modified-id=\"Word-Cloud-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Word Cloud</a></span></li><li><span><a href=\"#Sentiment-Analysis\" data-toc-modified-id=\"Sentiment-Analysis-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Sentiment Analysis</a></span></li></ul></li><li><span><a href=\"#Let's-make-a-function!\" data-toc-modified-id=\"Let's-make-a-function!-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let's make a function!</a></span><ul class=\"toc-item\"><li><span><a href=\"#By-user\" data-toc-modified-id=\"By-user-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>By user</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "<h1>Take notice!</h1>\n",
    "<ul>\n",
    "    <li>Make sure you are working with a copy and not the original notebook file</li>\n",
    "    <li>This class will be recorded</li>\n",
    "</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "For this lab, we will look at a way to use python to analyze qualitative data. This lab will:\n",
    "\n",
    "- import twitter data\n",
    "- create word clouds\n",
    "- conduct sentiment analysis\n",
    "\n",
    "We will use the following libraries:\n",
    "\n",
    "- [tweepy](http://docs.tweepy.org/en/v3.9.0/getting_started.html) to bring twitter into our notebooks\n",
    "- [word_cloud](https://github.com/amueller/word_cloud) to create word clouds\n",
    "- [textblob](https://textblob.readthedocs.io/en/dev/) for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bring in the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the regulars\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import osmnx as ox\n",
    "\n",
    "# to get tweets\n",
    "import tweepy as tw\n",
    "\n",
    "# for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# word clouds\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Twitter with tweepy\n",
    "\n",
    "In order to use twitter's api, you will need a [developer's account](https://developer.twitter.com/en/apply-for-access). You will then have the ability to generate the tokens needed to use their API.\n",
    "\n",
    "- http://docs.tweepy.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# your twitter keys/secrets/tokens\n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# authenticate thyself with twitter\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by username\n",
    "- http://docs.tweepy.org/en/latest/api.html#API.user_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.user_timeline, id='BillGates', tweet_mode='extended').items(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by keyword\n",
    "\n",
    "* search parameters: http://docs.tweepy.org/en/latest/api.html#search-methods\n",
    "* [rules and filetering](https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/overview/standard-operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# search query\n",
    "q = 'covid'\n",
    "\n",
    "# filter out retweets (optional of course)\n",
    "q = q + \" -filter:retweets\"\n",
    "\n",
    "# how many?\n",
    "max_tweets = 500\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.search,q=q, tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tweets by keyword and place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "                   q=q,\n",
    "                   geocode='34.068921,-118.4473751,50km', \n",
    "                   tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The tweet object\n",
    "\n",
    "So what does tweepy return? It returns an item iterator that allows us to loop and extract information. However, for reasons that I am unable to verify, the item iterator that is returned by the `tw.Cursor` function can only run a single loop operation before it mysteriously disappears (if anybody can figure this one out, let me know!). For that reason, let's run the search again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# search twitter (again)\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=q,\n",
    "                   geocode='34.068921,-118.4473751,50km', \n",
    "                   tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The tweet object is in *json* format. We can convert it into a dataframe for easier access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "json_data = [tweet._json for tweet in tweets]\n",
    "df = pd.json_normalize(json_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That's a lot of columns! Twitter saves a ton of metadata for each tweet... Let's clean this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['created_at','full_text','user.screen_name','user.profile_image_url_https']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['created_at','text','screen_name','profile_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# override the default so that we can see the entire text in the column\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just for fun, let's convert the profile image url's into actual images. This is somewhat of a hack, and only works with the applied code below (ie, it's not baked into the dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# library to display html images\n",
    "from IPython.display import Image, HTML\n",
    "\n",
    "# function to convert url to html image\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\"/>'\n",
    "\n",
    "HTML(df.to_html(escape=False ,formatters=dict(profile_image=path_to_image_html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Now it's your turn! Get creative and create your own twitter search queries on matters that interest you. Make sure that you end up with a dataframe named \"df\" to use for the word cloud below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Cloud\n",
    "Word clouds are great to visually display word clusters. The algorithms are simple. More word frequency, larger font size, less frequent words, smaller fonts sizes.\n",
    "\n",
    "We will use the [word_cloud library](https://github.com/amueller/word_cloud).\n",
    "\n",
    "First though, we need to clean up the tweets. Tweets are notorious for having strange characters and emoji's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# function to clean tweets using regular expressions\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# an example of cleaning a tweet\n",
    "tweet = df.sample().text.values[0]\n",
    "print(tweet)\n",
    "clean_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a new column for the clean text\n",
    "df['clean_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loop and add the cleaned up text to the new column\n",
    "for i, row in df.iterrows():\n",
    "    clean = clean_tweet(row.text)\n",
    "    df.at[i,'clean_text'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(5)[['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great. Every tweet has been cleaned up. In order to create a word cloud, we need to create a single variable that has every word in every tweet from our twitter dataframe. We then feed that to the world cloud factory that will generate the word cloud for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# now put every word into a single variable\n",
    "all_text = ' '.join(df['clean_text'])\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create the word cloud\n",
    "wordcloud = WordCloud(width=1200, \n",
    "                      height=800,\n",
    "                      background_color=\"white\").generate(all_text)\n",
    "\n",
    "# Display the WordCloud                    \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "<img src=\"https://monkeylearn.com/static/3ca10d6ce5dc6922836f278aef38f765/50bf7/what-is-sentiment-analysis6%402x.png\" width=400>\n",
    "\n",
    "[source](https://monkeylearn.com/sentiment-analysis/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For sentiment analysis, we will use the [textblob](https://textblob.readthedocs.io/en/dev/) python library.\n",
    "\n",
    "The sentiment property returns a tuple of the form `Sentiment(polarity, subjectivity)`. The polarity score ranges from -1 (most negative) to +1 (most positive). The subjectivity ranges from 0 to 1, where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Let's test this out on a random tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get a random tweet\n",
    "tweet = df.sample().clean_text.values[0]\n",
    "print(tweet)\n",
    "\n",
    "# analyze the tweet\n",
    "a = TextBlob(tweet)\n",
    "\n",
    "# results\n",
    "a.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create an new (empty) column for polarity\n",
    "df['polarity']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loop through every row and add the polarity value in our new column\n",
    "for i, row in df.iterrows():\n",
    "    a = TextBlob(row.text)\n",
    "    df.at[i,'polarity'] = a.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[['clean_text','polarity']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's quantify the results. Tweets are either positive, neutral, or negative, so let's give them categorical values.\n",
    "\n",
    "Numpy has a convenient function `.select` that allows you to generate a categorical ranking based on conditional arguments on a given column. In other words, we can assign tweets to be \"positive\" or \"negative\" based on their polarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df['polarity'] < 0), # negative\n",
    "    (df['polarity'] == 0), # neutral\n",
    "    (df['polarity'] > 0) # positive\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [\n",
    "    'negative', \n",
    "    'neutral', \n",
    "    'positive'\n",
    "    ]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['sentiment'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# display updated DataFrame\n",
    "df.sample(5)[['clean_text','polarity','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pie chart\n",
    "fig = px.pie(df, \n",
    "             names='sentiment',\n",
    "             width=600,\n",
    "             title='Sentiment analysis for '+q,\n",
    "             color='sentiment',\n",
    "             color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "            )\n",
    "fig.update_traces(textinfo='value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# histogram\n",
    "num_bins = 50\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of polarity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's make a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def find_tweets(q,place,distance='50km',count=500):\n",
    "    \n",
    "    #\n",
    "    # geocode the place to get coordinates\n",
    "    #\n",
    "    \n",
    "    g = ox.geocoder.geocode(place)\n",
    "    \n",
    "    # concatenate the results\n",
    "    geocode = '\"'+str(g[0])+','+str(g[1])+','+distance+'\"'\n",
    "    \n",
    "    #\n",
    "    # grab the tweets\n",
    "    #\n",
    "    \n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q=q+' -filter:retweets', # no retweets\n",
    "                       geocode=geocode, \n",
    "                       tweet_mode='extended').items(count)\n",
    "    #\n",
    "    # create a dataframe\n",
    "    #\n",
    "    \n",
    "    json_data = [tweet._json for tweet in tweets]\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # clean it up\n",
    "    df = df[['created_at','full_text']]\n",
    "\n",
    "    # clean the text\n",
    "    df['clean_text'] = ''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        clean = clean_tweet(row.full_text)\n",
    "        df.at[i,'clean_text'] = clean\n",
    "\n",
    "    #\n",
    "    # word cloud\n",
    "    #\n",
    "    \n",
    "    all_text = ' '.join(df['clean_text'])\n",
    "    \n",
    "    # create the word cloud\n",
    "    wordcloud = WordCloud(width=1200, \n",
    "                          height=800,\n",
    "                          background_color=\"white\").generate(all_text)\n",
    "\n",
    "    # Display the WordCloud                    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # sentiment analysis\n",
    "    #\n",
    "    \n",
    "    df['polarity']=''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        a = TextBlob(row.full_text)\n",
    "        df.at[i,'polarity'] = a.polarity\n",
    "    \n",
    "    # create a list of our conditions\n",
    "    \n",
    "    conditions = [\n",
    "        (df['polarity'] < 0), # negative\n",
    "        (df['polarity'] == 0), # neutral\n",
    "        (df['polarity'] > 0) # positive\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [\n",
    "        'negative', \n",
    "        'neutral', \n",
    "        'positive'\n",
    "        ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "    fig = px.pie(df, \n",
    "                 names='sentiment',\n",
    "                 width=600,\n",
    "                 title='Sentiment analysis for '+q,\n",
    "                 color='sentiment',\n",
    "                 color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "                )\n",
    "    fig.update_traces(textinfo='value')\n",
    "    fig.show()\n",
    "    \n",
    "    num_bins = 50\n",
    "    plt.figure(figsize=(10,6))\n",
    "    n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.xlabel('Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Average polarity: '+str(df.polarity.mean()))\n",
    "    plt.show()\n",
    "    \n",
    "    top10 = df.sort_values('polarity').head(10)[['clean_text','polarity']]\n",
    "    bottom10 = df.sort_values('polarity').tail(10)[['clean_text','polarity']]\n",
    "    \n",
    "    display('Top 10 positive tweets')\n",
    "    display(top10)\n",
    "    \n",
    "    display('Top 10 negative tweets')\n",
    "    display(bottom10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "find_tweets(q='masks',place='90095')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## By user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def find_tweets_user(u,count=500):\n",
    "    \n",
    "    #\n",
    "    # grab the tweets\n",
    "    #\n",
    "    tweets = tw.Cursor(api.user_timeline, \n",
    "                       id=u, \n",
    "                       tweet_mode='extended').items(count)\n",
    "    \n",
    "    #\n",
    "    # create a dataframe\n",
    "    #\n",
    "    \n",
    "    json_data = [tweet._json for tweet in tweets]\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # clean it up\n",
    "    df = df[['created_at','full_text']]\n",
    "\n",
    "    # clean the text\n",
    "    df['clean_text'] = ''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        clean = clean_tweet(row.full_text)\n",
    "        df.at[i,'clean_text'] = clean\n",
    "\n",
    "    #\n",
    "    # word cloud\n",
    "    #\n",
    "    \n",
    "    all_text = ' '.join(df['clean_text'])\n",
    "    \n",
    "    # create the word cloud\n",
    "    wordcloud = WordCloud(width=1200, \n",
    "                          height=800,\n",
    "                          background_color=\"white\").generate(all_text)\n",
    "\n",
    "    # Display the WordCloud                    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # sentiment analysis\n",
    "    #\n",
    "    \n",
    "    df['polarity']=''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        a = TextBlob(row.full_text)\n",
    "        df.at[i,'polarity'] = a.polarity\n",
    "    \n",
    "    # create a list of our conditions\n",
    "    \n",
    "    conditions = [\n",
    "        (df['polarity'] < 0), # negative\n",
    "        (df['polarity'] == 0), # neutral\n",
    "        (df['polarity'] > 0) # positive\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [\n",
    "        'negative', \n",
    "        'neutral', \n",
    "        'positive'\n",
    "        ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "    fig = px.pie(df, \n",
    "                 names='sentiment',\n",
    "                 width=600,\n",
    "                 title='Sentiment analysis for '+q,\n",
    "                 color='sentiment',\n",
    "                 color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "                )\n",
    "    fig.update_traces(textinfo='value')\n",
    "    fig.show()\n",
    "    \n",
    "    num_bins = 50\n",
    "    plt.figure(figsize=(10,6))\n",
    "    n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.xlabel('Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Average polarity: '+str(df.polarity.mean()))\n",
    "    plt.show();\n",
    "    return df.sample(5)[['clean_text','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "find_tweets_user(u='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "find_tweets_user(u='JoeBiden')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
